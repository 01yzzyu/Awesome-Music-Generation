# Music


| Date       | Keywords   | Institute (first) | Paper                                                                                                                          | Publication | Code | 
| ---------- | ---------- | ----------------- | ------------------------------------------------------------------------------------------------------------------------------ | ----------- | ---- | 
| 2024-11-06 |  | CMU | [Aligning Audio-Visual Joint Representations with an Agentic Workflow](https://openreview.net/forum?id=NGrINZyZKk) | NIPS 2024 | Github | 
| 2024-11-06 | | Polytechnic Institute of Paris | [An Eye for an Ear: Zero-shot Audio Description Leveraging an Image Captioner using Audiovisual Distribution Alignment](https://openreview.net/pdf?id=U6oQEzSp8z) | NIPS 2024 | [Github](https://github.com/hugomalard/AnEyeForAnEar) | 
| 2024-11-06 | UniAudio 1.5 | CUHKSZ | [UniAudio 1.5: Large Language Model-Driven Audio Codec is A Few-Shot Audio Task Learner](https://openreview.net/forum?id=QMaLS4VeY3) | NIPS 2024 | [Github](https://github.com/yangdongchao/LLM-Codec) | 
| 2024-10-19 | Vevo | SHAI Lab| [Vevo: Controllable Zero-Shot Voice Imitation with Self-Supervised Disentanglement](https://openreview.net/pdf?id=anQDiQZhDP) | ICLR 2025 | [Github](https://github.com/open-mmlab/Amphion/blob/main/models/vc/vevo/README.md) | 
| 2024-10-19 | MaskGCT | CUHKSZ | [MaskGCT: Zero-Shot Text-to-Speech with Masked Generative Codec Transformer](https://arxiv.org/pdf/2409.00750) | ICLR 2025 | [Github](https://github.com/open-mmlab/Amphion/tree/main/models/tts/maskgct) | 
| 2025-10-04 | Audio-Agent | HKUST | [Audio-Agent: Leveraging LLMs for Audio Generation, Editing and Composition](https://arxiv.org/pdf/2410.03335) | Arxiv 2024 | Github | 
| 2024-10-07 |  | Tsinghua | [Editing Music with Melody and Text: Using ControlNet for Diffusion Transformer](https://arxiv.org/abs/2410.05151) | ICASSP 2025 | Github | 
| 2024-09-19 | AudioComposer | CUHK | [AudioComposer: Towards Fine-grained Audio Generation with Natural Language Descriptions](https://arxiv.org/abs/2409.12560) | Arxiv 2024 | [Github](https://lavendery.github.io/AudioComposer/) | 
| 2024-07-31 |  | Sorbonne Université | [Combining audio control and style transfer using latent diffusion](https://arxiv.org/abs/2408.00196) | ISMIR 2024 | [Github](https://github.com/NilsDem/control-transfer-diffusion) | 
| 2024-07-23 | Audio Prompt Adapter | National Taiwan University | [Audio Prompt Adapter: Unleashing Music Editing Abilities for Text-to-Music with Lightweight Finetuning](https://arxiv.org/abs/2407.16564) | ISMIR 2024 | [Github](https://github.com/fundwotsai2001/ap-adapter)  |  
| 2024-07-23 | Meerkat |  Maryland | [Meerkat: Audio-Visual Large Language Model for Grounding in Space and Time](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/08071.pdf) | ECCV 2024 | [Github](https://github.com/schowdhury671/meerkat)  |  
| 2024-07-17 | FoleyCrafter| SHAI Lab | [FoleyCrafter: Bring Silent Videos to Life with Lifelike and Synchronized Sounds](https://arxiv.org/abs/2407.01494) | Arxiv 2024 | [Github](https://github.com/open-mmlab/foleycrafter) |  
| 2024-06-07 | MeLFusion | Maryland | [MeLFusion: Synthesizing Music from Image and Language Cues using Diffusion Models](https://arxiv.org/abs/2406.04673) | CVPR 2024 Highlight | [Github](https://schowdhury671.github.io/melfusion_cvpr2024/)  |  
| 2025-06-07 | ControlSpeech | ZJU | [ControlSpeech: Towards Simultaneous Zero-shot Speaker Cloning and Zero-shot Language Style Control With Decoupled Codec](https://arxiv.org/abs/2406.01205) | Arxiv 2024 | [Github](https://github.com/jishengpeng/ControlSpeech) | 
| 2025-06-06 | VidMuse | HKUST | [VidMuse: A Simple Video-to-Music Generation Framework with Long-Short-Term Modeling](https://arxiv.org/pdf/2406.04321) | Arxiv 2024 | [Github](https://github.com/zeyuet/vidmuse) | 
| 2024-04-19 | Tango 2 | SUTD | [Tango 2: Aligning Diffusion-based Text-to-Audio Generations through Direct Preference Optimization](https://arxiv.org/abs/2404.09956) | MM 2024 Oral | [Github](https://github.com/declare-lab/tango)  | 
| 2024-02-17 |  | HKUST | [Open-domain Visual-Audio Generation with Diffusion Latent Aligners](https://arxiv.org/abs/2402.17723) | CVPR 2024 | [Github](https://github.com/yzxing87/Seeing-and-Hearing)  | 
| 2024-02-07 | BATON | Tsinghua | [BATON: Aligning Text-to-Audio Model with Human Preference Feedback](https://arxiv.org/abs/2402.00744) | IJCAI 2024 | [Github](https://github.com/Hannieliao/Baton)  | 
| 2024-01-07 | Auffusion | BUPT | [Auffusion: Leveraging the Power of Diffusion and Large Language Models for Text-to-Audio Generation](https://arxiv.org/abs/2406.04673) | CVPR 2024 Highlight | [Github](https://auffusion.github.io/)  |  
| 2023-05-29 | Make-An-Audio 2 | ZJU | [Make-An-Audio 2: Temporal-Enhanced Text-to-Audio Generation](https://arxiv.org/abs/2305.18474) | Arxiv 2023 | [Github](https://github.com/bytedance/Make-An-Audio-2)  | 

